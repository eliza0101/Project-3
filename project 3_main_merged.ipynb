{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User Input and Image Generation**\n",
    "\n",
    "Steps with Gradio:\n",
    "1. Ask User for Image Concepts: Use Gradio to create a text input interface where users can enter their image concepts.\n",
    "2. Clean User Input: Ensure the prompt is clean of unnecessary spaces or characters.\n",
    "3. Prompt the Image Generation Agent: Call APIs to generate images using Stable Diffusion XL and DALL-E based on user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "# For environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#For dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# For API calls\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "# For image processing and viewing\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For UI\n",
    "import gradio as gr\n",
    "\n",
    "# For caption generation\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Load dependencies to measure text output\n",
    "import nltk\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# BLEU Score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Store the API key in a variable.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "STABILITY_AI_API_KEY = os.getenv(\"STABILITY_AI_API_KEY\")\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to view images for debugging\n",
    "def view_base64_image(base64_string):\n",
    "    \"\"\"Decodes a base64 encoded image and displays it using matplotlib.\"\"\"\n",
    "\n",
    "    # Decode the base64 string\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to clean user input by removing extra spaces\n",
    "def clean_user_input(user_query):\n",
    "    cleaned_query = ' '.join(user_query.split())\n",
    "    return cleaned_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Stability AI API and generate an image\n",
    "def generate_stability_ai_image(prompt):\n",
    "    host = 'https://api.stability.ai/v2beta/stable-image/generate/sd3'\n",
    "    params = {\n",
    "        \"prompt\" : prompt,\n",
    "        \"negative_prompt\" : '',\n",
    "        \"aspect_ratio\" : '1:1',\n",
    "        \"seed\" : 0,\n",
    "        \"output_format\" : 'jpeg',\n",
    "        \"model\" : \"sd3\",\n",
    "        \"mode\" : \"text-to-image\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\": \"image/*\",\n",
    "        \"Authorization\": f\"Bearer {STABILITY_AI_API_KEY}\"\n",
    "    }\n",
    "\n",
    "    # Encode parameters\n",
    "    files = {}\n",
    "    image = params.pop(\"image\", None)\n",
    "    mask = params.pop(\"mask\", None)\n",
    "    if image is not None and image != '':\n",
    "        files[\"image\"] = open(image, 'rb')\n",
    "    if mask is not None and mask != '':\n",
    "        files[\"mask\"] = open(mask, 'rb')\n",
    "    if len(files)==0:\n",
    "        files[\"none\"] = ''\n",
    "\n",
    "    # Send request\n",
    "    print(f\"Sending REST request to {host}...\")\n",
    "    response = requests.post(\n",
    "        host,\n",
    "        headers=headers,\n",
    "        files=files,\n",
    "        data=params\n",
    "    )\n",
    "    if not response.ok:\n",
    "        raise Exception(f\"HTTP {response.status_code}: {response.text}\")\n",
    "\n",
    "    return base64.b64encode(response.content)\n",
    "    # To test the function: response = generate_stability_ai_image(\"cute shiba inu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Dall-E Open AI API and generate an image\n",
    "def call_dalle_api(prompt):\n",
    "    client = openai.OpenAI()\n",
    "    response = client.images.generate(\n",
    "    model=\"dall-e-2\",\n",
    "    prompt=prompt,\n",
    "    size=\"512x512\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "    response_format=\"b64_json\"\n",
    "    )\n",
    "\n",
    "    return response.data[0].b64_json\n",
    "    # To test the function: response = call_dalle_api(\"A realistic image of a shiba inu with a birthday hat on the street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert base64 string to a PIL Image object\n",
    "def base64_to_pil_image(base64_string):\n",
    "\n",
    "    # Decode the base64 string\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "\n",
    "    # Create a BytesIO object from the decoded data\n",
    "    image_bytes = BytesIO(image_data)\n",
    "\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_bytes)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generate images and assess their quality\n",
    "def generate_images_with_quality(prompt):\n",
    "    cleaned_prompt = clean_user_input(prompt)\n",
    "    stability_ai_image = base64_to_pil_image(generate_stability_ai_image(cleaned_prompt))\n",
    "    dalle_image = base64_to_pil_image(call_dalle_api(cleaned_prompt))\n",
    "\n",
    "    timestamp = time.time()\n",
    "    \n",
    "    with open(f\"generated_images/{timestamp}_prompt.txt\", \"w\") as f:\n",
    "        # Write text to the file\n",
    "        f.write(f'{prompt}, {cleaned_prompt}')\n",
    "        \n",
    "    stability_ai_image.save(f'generated_images/{timestamp}_stability_ai.jpg')\n",
    "    dalle_image.save(f'generated_images/{timestamp}_dalle.jpg')\n",
    "\n",
    "    #sd_quality = assess_image_quality(sd_image)\n",
    "    #dalle_quality = assess_image_quality(dalle_image)\n",
    "    return stability_ai_image, dalle_image #, f\"Quality: {sd_quality}\", dalle_image, f\"Quality: {dalle_quality}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://9ec2ee4c85ff9c85cc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9ec2ee4c85ff9c85cc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending REST request to https://api.stability.ai/v2beta/stable-image/generate/sd3...\n"
     ]
    }
   ],
   "source": [
    "# Gradio interface setup for user interaction\n",
    "iface = gr.Interface(fn=generate_images_with_quality,\n",
    "                     inputs=\"text\",\n",
    "                     outputs=[gr.Image(type=\"pil\", label=\"Stability AI Image\"), gr.Image(type=\"pil\", label=\"Dall-E Image\")],\n",
    "                     title=\"Text-to-Image Generation\",\n",
    "                     description=\"Input a concept to generate images using Stability AI and Dall-E.\")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Evaluation, Relevance Check, and Description Generation**\n",
    "\n",
    "Steps:\n",
    "1. Evaluate Image Relevance: Use an LLM to assess whether the generated image is relevant to the prompt.\n",
    "2. Generate Image Descriptions: Use a classifier to create descriptive summaries of the images.\n",
    "3. Compare Models: Analyze how each model's output aligns with the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for caption generation\n",
    "def generate_caption(image):\n",
    "    # Process the image and generate a caption\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompt for images\n",
    "prompt_file = open('generated_images/1730005832.2413912_prompt.txt')\n",
    "prompt = prompt_file.read().split(',')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate caption for Stability AI image\n",
    "img = Image.open(\"generated_images/1730005832.2413912_stability_ai.jpg\")\n",
    "stability_ai_caption = generate_caption(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate caption for Dall-E image\n",
    "img = Image.open(\"generated_images/1730005832.2413912_dalle.jpg\")\n",
    "dalle_caption = generate_caption(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Stability AI BLEU score\n",
    "# Prompted captions and generated captions\n",
    "reference_captions = [prompt]\n",
    "generated_captions = [stability_ai_caption]\n",
    "\n",
    "# Calculate BLEU scores for each pair of reference and generated captions\n",
    "bleu_scores = [sentence_bleu([ref.split()], gen.split()) for ref, gen in zip(reference_captions, generated_captions)]\n",
    "\n",
    "# Calculate the average BLEU score\n",
    "stability_ai_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "# Print the average BLEU score\n",
    "print(f\"Average BLEU Score: {stability_ai_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Dall-E BLEU score\n",
    "# Prompted captions and generated captions\n",
    "reference_captions = [prompt]\n",
    "generated_captions = [dalle_caption]\n",
    "\n",
    "# Calculate BLEU scores for each pair of reference and generated captions\n",
    "bleu_scores = [sentence_bleu([ref.split()], gen.split()) for ref, gen in zip(reference_captions, generated_captions)]\n",
    "\n",
    "# Calculate the average BLEU score\n",
    "dalle_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "# Print the average BLEU score\n",
    "print(f\"Average BLEU Score: {dalle_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Rouge score\n",
    "def calculate_rouge(reference, generated):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Stability AI ROUGE Score\n",
    "reference_captions = [prompt]\n",
    "generated_captions = [stability_ai_caption]\n",
    "for ref, gen in zip(reference_captions, generated_captions):\n",
    "    stability_ai_rouge_score = calculate_rouge(ref, gen)\n",
    "    print(f\"ROUGE scores for reference: '{ref}' and generated: '{gen}': {stability_ai_rouge_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Dall-E ROUGE Score\n",
    "reference_captions = [prompt]\n",
    "generated_captions = [dalle_caption]\n",
    "for ref, gen in zip(reference_captions, generated_captions):\n",
    "    dalle_rouge_score = calculate_rouge(ref, gen)\n",
    "    print(f\"ROUGE scores for reference: '{ref}' and generated: '{gen}': {dalle_rouge_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunji need to clean up graph, don't need to recalculate score (?)\n",
    "\n",
    "# Plot results\n",
    "# Sample reference and generated captions\n",
    "reference_captions = [prompt, prompt]\n",
    "generated_captions = [stability_ai_caption, dalle_caption]\n",
    "\n",
    "# Calculate BLEU scores\n",
    "bleu_scores = [sentence_bleu([ref.split()], gen.split()) for ref, gen in zip(reference_captions, generated_captions)]\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge_scores = [scorer.score(ref, gen) for ref, gen in zip(reference_captions, generated_captions)]\n",
    "rouge1_scores = [score['rouge1'].fmeasure for score in rouge_scores]\n",
    "rouge2_scores = [score['rouge2'].fmeasure for score in rouge_scores]\n",
    "rougeL_scores = [score['rougeL'].fmeasure for score in rouge_scores]\n",
    "\n",
    "# Prepare data for K-means\n",
    "X = np.array(list(zip(bleu_scores, rouge1_scores)))\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=1)  # Choose number of clusters\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.title('K-means Clustering of BLEU and ROUGE Scores')\n",
    "plt.xlabel('BLEU Score')\n",
    "plt.ylabel('ROUGE-1 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce output\n",
    "# prompt, stability ai caption, dalle caption, stability ai relevance, dalle relevance\n",
    "file_output = open('image_generation_results.csv', 'a')\n",
    "file_output.write(f'\"{prompt}\",\"{stability_ai_caption}\",\"{dalle_caption}\",\"{stability_ai_bleu}\",\"{dalle_bleu}\",\"{stability_ai_rouge_score}\",\"{dalle_rouge_score}\"')\n",
    "file_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_csv('image_generation_results.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
